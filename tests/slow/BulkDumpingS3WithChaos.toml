# BulkDumping S3 with Chaos Injection Tests
#
# Overview:
# This test suite validates FoundationDB's bulk dump and bulk load functionality using S3-compatible
# storage (MockS3Server) under various fault injection scenarios.
#
# Bulk Dump/Load Workflow:
# 1. Bulk Dump: Exports a range of key-value data from FDB to SST files, uploads to S3
# 2. Bulk Load: Downloads SST files from S3, ingests into FDB storage servers via FetchKeys
#
# This bypasses normal transaction/replication paths for efficient large-scale data movement
# (e.g., cluster migrations, data imports, disaster recovery).
#
# Test Strategy:
# Runs 4 sequential tests with increasing chaos levels (Stable → Light → Medium → Heavy)
# to validate that bulk load operations:
# - Successfully retry transient S3 failures
# - Complete within reasonable timeouts despite delays/throttling
# - Maintain data integrity under corruption scenarios
# - Don't cause FetchKeys/DataDistribution to hang under stress

[configuration]
storageEngineExcludeTypes = [5] #FIXME: remove after allowing to do bulkloading with fetchKey and shardedrocksdb

disableTss = true # TODO(BulkLoad): support TSS. finishMoveShard should wait for TSS if a data move is bulkload data move.

# This test suite runs 4 tests sequentially: Stable (350s) + Light (648s) + Medium + Heavy
# Total runtime can exceed the default 5400s simulation timeout, so mark as longRunningTest
longRunningTest = true

# Instruct simulation to generate a simple, single-region config
generateFearless = false
simpleConfig = false

# Simple network configuration - single region, no satellites
minimumRegions = 1
# Use ssd-2 storage engine instead of rocksdb to avoid RocksDB bulk loading crashes
# The RocksDB assertion failure indicates incompatibility with current bulk loading implementation
config = "triple usable_regions=1 storage_engine=ssd-2 perpetual_storage_wiggle=0 commit_proxies=3 grv_proxies=3 resolvers=3 logs=3"

# Disable all fault injection and network failures
# buggify = false now controls ALL fault injection systems (BUGGIFY, failure workloads, AND global fault injection)
buggify = false

[[knobs]]
bulkload_sim_failure_injection = false
shard_encode_location_metadata = true
enable_read_lock_on_range = true
enable_version_vector = false
enable_version_vector_tlog_unicast = false
enable_version_vector_reply_recovery = false
min_byte_sampling_probability = 0.5
cc_enforce_use_unfit_dd_in_sim = true
disable_audit_storage_final_replica_check_in_sim = true
max_trace_lines = 5000000
dd_team_zero_server_left_log_delay = 0
dd_rebalance_parallelism = 1

[[flow_knobs]]
MAX_BUGGIFIED_DELAY = 0.0
blobstore_max_connection_life = 300
blobstore_request_timeout_min = 300
blobstore_request_tries = 5
blobstore_connect_tries = 5
blobstore_connect_timeout = 30
http_send_size = 1024
http_read_size = 1024
connection_monitor_loop_time = 0.1
connection_monitor_timeout = 1.0
connection_monitor_idle_timeout = 60.0

[[client_knobs]]
blobstore_max_delay_retryable_error = 2
blobstore_max_delay_connection_failed = 1

[[test]]
# BulkDumping with stable MockS3Server (no chaos injection)
testTitle = 'BulkDumpingS3Stable'
useDB = true
waitForQuiescence = false
connectionFailuresDisableDuration = 1000000
# Completely disable fault injection workloads to prevent operation_cancelled errors
runFailureWorkloads = false
# Increase timeout for bulk operations - S3 bulk dumps can be slow
timeout = 3600

    [[test.workload]]
    testName = 'BulkDumpingWorkload'
    # 2 is BulkLoadTransportMethod::BLOBSTORE (S3) - now using MockS3Server
    bulkLoadTransportMethod = 2
    # S3 URL for bulk dump/load operations using MockS3Server
    jobRoot = 'blobstore://testkey:testsecret:testtoken@127.0.0.1:8080/?bucket=bulkdumping&region=us-east-1&secure_connection=0&bypass_simulation=0&global_connection_pool=0&connect_timeout=60&request_timeout=120'
    maxCancelTimes = 0

[[test]]
# BulkDumping with light chaos injection
testTitle = 'BulkDumpingS3LightChaos'
useDB = true
waitForQuiescence = false
connectionFailuresDisableDuration = 1000000
runFailureWorkloads = false
# Increase timeout for chaos tests - 10 retries * 5s delay = 50s per failed op
timeout = 7200
# Increase max DD run time for consistency check - DD queue takes longer to drain with chaos
maxDDRunTime = 2400

    [[test.workload]]
    testName = 'BulkDumpingWorkload'
    bulkLoadTransportMethod = 2
    jobRoot = 'blobstore://testkey:testsecret:testtoken@127.0.0.1:8080/?bucket=bulkdumping&region=us-east-1&secure_connection=0&bypass_simulation=0&global_connection_pool=0&connect_timeout=60&request_timeout=120'
    maxCancelTimes = 0
    enableChaos = true
    # Light chaos: occasional failures to test retry logic
    errorRate = 0.03
    throttleRate = 0.02
    delayRate = 0.08
    corruptionRate = 0.01
    maxDelay = 0.5

[[test]]
# BulkDumping with medium chaos injection
testTitle = 'BulkDumpingS3MediumChaos'
useDB = true
waitForQuiescence = false
connectionFailuresDisableDuration = 1000000
runFailureWorkloads = false
# Increase timeout for chaos tests - 10 retries * 5s delay = 50s per failed op
timeout = 10800
# Increase max DD run time for consistency check - DD queue takes longer to drain with chaos
maxDDRunTime = 3600

    [[test.workload]]
    testName = 'BulkDumpingWorkload'
    bulkLoadTransportMethod = 2
    jobRoot = 'blobstore://testkey:testsecret:testtoken@127.0.0.1:8080/?bucket=bulkdumping&region=us-east-1&secure_connection=0&bypass_simulation=0&global_connection_pool=0&connect_timeout=60&request_timeout=120'
    maxCancelTimes = 0
    enableChaos = true
    # Medium chaos: moderate failure rate to stress test retry logic
    errorRate = 0.08
    throttleRate = 0.05
    delayRate = 0.15
    corruptionRate = 0.02
    maxDelay = 1.0

[[test]]
# BulkDumping with heavy chaos injection
testTitle = 'BulkDumpingS3HeavyChaos'
useDB = true
waitForQuiescence = false
connectionFailuresDisableDuration = 1000000
runFailureWorkloads = false
# Increase timeout for chaos tests - 10 retries * 5s delay = 50s per failed op
timeout = 14400
# Increase max DD run time for consistency check - DD queue takes longer to drain with heavy chaos
maxDDRunTime = 5400

    [[test.workload]]
    testName = 'BulkDumpingWorkload'
    bulkLoadTransportMethod = 2
    jobRoot = 'blobstore://testkey:testsecret:testtoken@127.0.0.1:8080/?bucket=bulkdumping&region=us-east-1&secure_connection=0&bypass_simulation=0&global_connection_pool=0&connect_timeout=60&request_timeout=120'
    maxCancelTimes = 0
    enableChaos = true
    # Heavy chaos: high failure rate to thoroughly test resilience
    errorRate = 0.15
    throttleRate = 0.10
    delayRate = 0.25
    corruptionRate = 0.03
    maxDelay = 2.0

